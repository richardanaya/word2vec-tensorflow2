{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"king is a strong man\", \n",
    "    \"queen is a wise woman\", \n",
    "    \"boy is a young man\", \n",
    "    \"girl is a young woman\", \n",
    "    \"prince is a young king\", \n",
    "    \"princess is a young queen\", \n",
    "    \"man is strong\", \n",
    "    \"woman is pretty\", \n",
    "    \"prince is a boy will be king\", \n",
    "    \"princess is a girl will be queen\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsefulWords(sentence):\n",
    "    allWords = sentence.split()\n",
    "    allDistinctWords = set(allWords)\n",
    "    uselessWords = {\"the\",\"is\",\"be\",\"will\",\"a\"}\n",
    "    allDistinctUsefulWords = list(filter(lambda a: a not in uselessWords, allDistinctWords))\n",
    "    return allDistinctUsefulWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boy': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'king': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'woman': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'girl': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'strong': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'princess': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'prince': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'man': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'pretty': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'queen': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'wise': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'young': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "allSentenceWordLists = list(map(lambda s: getUsefulWords(s) , sentences))\n",
    "allUniqueWords = set([item for sublist in allSentenceWordLists for item in sublist])\n",
    "def makeHotEncoding(i):\n",
    "    arr = [0]*len(allUniqueWords)\n",
    "    arr[i] = 1\n",
    "    return arr\n",
    "hotEncodings = {element: makeHotEncoding(i) for i,element in enumerate(allUniqueWords)} \n",
    "print(hotEncodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(items):\n",
    "    neighbors = []\n",
    "    if len(items) == 1:\n",
    "        return neighbors\n",
    "    for i,item in enumerate(items):\n",
    "        if i != 0:\n",
    "            neighbors.append([items[i],items[i-1]])\n",
    "        if i != len(items)-1:\n",
    "            neighbors.append([items[i],items[i+1]])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['man', 'strong'], ['strong', 'man'], ['strong', 'king'], ['king', 'strong'], ['queen', 'wise'], ['wise', 'queen'], ['wise', 'woman'], ['woman', 'wise'], ['man', 'boy'], ['boy', 'man'], ['boy', 'young'], ['young', 'boy'], ['young', 'woman'], ['woman', 'young'], ['woman', 'girl'], ['girl', 'woman'], ['prince', 'king'], ['king', 'prince'], ['king', 'young'], ['young', 'king'], ['queen', 'princess'], ['princess', 'queen'], ['princess', 'young'], ['young', 'princess'], ['man', 'strong'], ['strong', 'man'], ['woman', 'pretty'], ['pretty', 'woman'], ['king', 'prince'], ['prince', 'king'], ['prince', 'boy'], ['boy', 'prince'], ['girl', 'princess'], ['princess', 'girl'], ['princess', 'queen'], ['queen', 'princess']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-eb24c424dd9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mallNeighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallSentenceNeighborLists\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallNeighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhotEncodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallNeighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhotEncodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallNeighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "allSentenceNeighborLists = list(map(lambda s: getNeighbors(getUsefulWords(s)) , sentences))\n",
    "allNeighbors = [item for sublist in allSentenceNeighborLists for item in sublist]\n",
    "print(allNeighbors)\n",
    "inputs = tf.convert_to_tensor(list(map(lambda s: hotEncodings[s[0]], allNeighbors)),dtype=tf.float32)\n",
    "outputs = tf.convert_to_tensor(list(map(lambda s:hotEncodings[s[1]], allNeighbors)),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 2)           24        \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "vocab_size = len(allUniqueWords)\n",
    "embedding_dim=2\n",
    "\n",
    "maxlen = 500\n",
    "model = keras.Sequential([\n",
    "  layers.Embedding(vocab_size, embedding_dim),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    inputs,\n",
    "    outputs,\n",
    "    epochs=20000,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "lookup = list(map(lambda s: {'name':s[0],'x':s[1][0],'y':s[1][1]}, zip(allUniqueWords,weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x_min = 0\n",
    "y_min = 0\n",
    "x_max = 0\n",
    "y_max = 0\n",
    "x_data = []\n",
    "y_data = []\n",
    "for e in lookup:\n",
    "    x_data.append(e['x'])\n",
    "    y_data.append(e['y'])\n",
    "    x_min = min(x_min,e['x'])\n",
    "    y_min = min(y_min,e['y'])\n",
    "    x_max = max(x_max,e['x'])\n",
    "    y_max = max(y_max,e['y'])\n",
    "    ax.annotate(e['name'],(e['x'],e['y']))\n",
    "x_pad = abs(x_max-x_min)*.1\n",
    "y_pad = abs(y_max-y_min)*.1\n",
    "    \n",
    "plt.xlim(x_min-x_pad,x_max+x_pad)\n",
    "plt.ylim(y_min-y_pad,y_max+y_pad)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.scatter(x_data,y_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
